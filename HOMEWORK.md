# HOMEWORK.md

## 質問設計の観点と意図

本課題では、RAG（Retrieval-Augmented Generation）による情報検索の有効性を検証するために、5つの質問を自作した。  
うち4問は一般的な知識を問うもので、LLM単体でも一定の精度が期待できる設計とした。一方で、5問目には「2024年3月に京都大学で開催された医療AIカンファレンスに関する技術的内容」という、LLMの訓練データに含まれない可能性が高い情報を含めることで、RAGの恩恵が顕著に出るような設計とした。

---

## RAGの実装方法と工夫点

RAGの構成は以下のとおり：

- ベースモデル：`generate_output()` により、質問・コンテキストに基づく出力を生成
- 埋め込みモデル：HuggingFaceのSentenceTransformer（`all-MiniLM-L6-v2`）を使用
- 類似文検索：クエリと文書をベクトル化し、コサイン類似度によりTop-kの文書を抽出
- 文書チャンク処理：関連文の前後2文を含めた5文単位で文脈を形成
- 関連性フィルタリング：各チャンクが質問と関連しているかをLLMに判断させ、「yes」のものだけを参照資料として使用

### 工夫点

- 質問文に対して「参考資料が関連しているか？」を自動判定することで、ノイズの少ない参照文をLLMに与える工夫を行った
- 出力あり／なしのノートブックを分けて作成（`rag_main.ipynb` はコードのみ、`rag_main_demo.ipynb` は出力付き）

---

## 結果の分析と考察

- 今回の質問は全体的に簡単だったため、**RAGの方式を変えても出力に大きな違いはなかった**
- しかし、**RAGを実装することで回答の精度は明らかに向上**した
- 特に質問5（カンファレンスの技術）では、RAGを使わないとLLMが冗長な説明を返す傾向があった。これは、答えが汎用的な単語で言い換えられず、モデルが曖昧に補完しようとした結果と考えられる
- 文書フィルタリングを加えることで、生成される回答の一貫性と妥当性が向上した

---

## 発展的な改善案（任意）

- 回答の正確さ（answer accuracy）を自動的に判定する手法として、LLMベースの評価スコア（例：RAGASなど）を今後導入したい
- また、現在はretrieverとgeneratorが固定であるため、retrieverのアルゴリズム（例：BM25やHybrid Retrieval）や、chunkingの分割方法（意味ベース分割など）も今後比較検討の余地がある
- 実際にRAGによって「どの文が引用されているか」を明示的に表示する仕組みも今後のUI面で有用と考えられる

---

## 備考

- `rag_main.ipynb`：コードのみの実装（GitHubで開いて確認可能）
- `rag_main_demo.ipynb`：出力付きだがGitHubでは開けないため、Colab推奨
- `data/knowledge.txt`：質問に対する参照文を記載
- **質問文・参考文献の内容は、指示に基づいてLLMに出力させた**
- **本レポート（HOMEWORK.md）も、含めるべき内容の指示を与えた上でLLMによって生成した**
